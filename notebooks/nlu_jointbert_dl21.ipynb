{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "nlu_jointbert_dl21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzZzR2-U43r4"
      },
      "source": [
        "# Joint Intent Classification and Slot filling with BERT\n",
        "This notebook is based on the paper __BERT for Joint Intent Classification and Slot Filling__ by Chen et al. (2019), https://arxiv.org/abs/1902.10909 but on a different dataset made for a class project.\n",
        "\n",
        "Ideas were also taken from https://github.com/monologg/JointBERT, which is a PyTorch implementation of the paper with the original dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjRqJ7sS5vsQ"
      },
      "source": [
        "## Install transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OO2HRXgV5HA",
        "outputId": "c783f199-c246-4b52-e5ff-c650f3e03019"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbLDTz7m5_rs"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj_x96qa6C20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8fc8ee-90f2-470b-b65a-ecb22b253b80"
      },
      "source": [
        "!wget https://github.com/ShawonAshraf/nlu-jointbert-dl2021/raw/main/data/nlu_traindev/train.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-29 16:53:59--  https://github.com/ShawonAshraf/nlu-jointbert-dl2021/raw/main/data/nlu_traindev/train.json\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ShawonAshraf/nlu-jointbert-dl2021/main/data/nlu_traindev/train.json [following]\n",
            "--2021-01-29 16:53:59--  https://raw.githubusercontent.com/ShawonAshraf/nlu-jointbert-dl2021/main/data/nlu_traindev/train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5055766 (4.8M) [text/plain]\n",
            "Saving to: ‘train.json.3’\n",
            "\n",
            "\rtrain.json.3          0%[                    ]       0  --.-KB/s               \rtrain.json.3        100%[===================>]   4.82M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-01-29 16:54:00 (95.0 MB/s) - ‘train.json.3’ saved [5055766/5055766]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-T_1uc46O6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2154ec-0efa-46bd-8f72-b3c25746fd63"
      },
      "source": [
        "!wget https://github.com/ShawonAshraf/nlu-jointbert-dl2021/raw/main/data/nlu_traindev/dev.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-29 16:54:00--  https://github.com/ShawonAshraf/nlu-jointbert-dl2021/raw/main/data/nlu_traindev/dev.json\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ShawonAshraf/nlu-jointbert-dl2021/main/data/nlu_traindev/dev.json [following]\n",
            "--2021-01-29 16:54:00--  https://raw.githubusercontent.com/ShawonAshraf/nlu-jointbert-dl2021/main/data/nlu_traindev/dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248459 (243K) [text/plain]\n",
            "Saving to: ‘dev.json.3’\n",
            "\n",
            "\rdev.json.3            0%[                    ]       0  --.-KB/s               \rdev.json.3          100%[===================>] 242.64K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-01-29 16:54:00 (42.2 MB/s) - ‘dev.json.3’ saved [248459/248459]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpJIziCh6oy8"
      },
      "source": [
        "## Read data from json files\n",
        "\n",
        "Data is of the following format\n",
        "````json5\n",
        "{\n",
        "  \"text\": \"\",\n",
        "  \"positions\": [{}],\n",
        "  \"slots\": [{}],\n",
        "  \"intent\": \"\"\n",
        "}\n",
        "````\n",
        "\n",
        "We will be using `text` as the input and `slots` and `intent` as lables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqYLzmWhVT84"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "class RawData(object):\n",
        "    def __init__(self, id, intent, positions, slots, text):\n",
        "        self.id = id\n",
        "        self.intent = intent\n",
        "        self.positions = positions\n",
        "        self.slots = slots\n",
        "        self.text = text\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(json.dumps(self.__dict__, indent=2))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "reads json from data file\n",
        "returns a list containing DataInstance objects\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def read_train_json_file(filename):\n",
        "    if os.path.exists(filename):\n",
        "        intents = []\n",
        "\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as json_file:\n",
        "            data = json.load(json_file)\n",
        "\n",
        "            for k in data.keys():\n",
        "                intent = data[k][\"intent\"]\n",
        "                positions = data[k][\"positions\"]\n",
        "                slots = data[k][\"slots\"]\n",
        "                text = data[k][\"text\"]\n",
        "\n",
        "                temp = RawData(k, intent, positions, slots, text)\n",
        "                intents.append(temp)\n",
        "\n",
        "        return intents\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No file found with that path!\")\n",
        "\n",
        "# read from json file\n",
        "train_data = read_train_json_file(\"train.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgnD-4G3VT84",
        "outputId": "b97b2f95-64b3-4aff-9fd7-7586467a2dc2"
      },
      "source": [
        "example = train_data[0]\n",
        "example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"id\": \"0\",\n",
              "  \"intent\": \"AddToPlaylist\",\n",
              "  \"positions\": {\n",
              "    \"music_item\": [\n",
              "      6,\n",
              "      9\n",
              "    ],\n",
              "    \"playlist_owner\": [\n",
              "      14,\n",
              "      15\n",
              "    ],\n",
              "    \"playlist\": [\n",
              "      17,\n",
              "      32\n",
              "    ]\n",
              "  },\n",
              "  \"slots\": {\n",
              "    \"music_item\": \"tune\",\n",
              "    \"playlist_owner\": \"my\",\n",
              "    \"playlist\": \"elrow Guest List\"\n",
              "  },\n",
              "  \"text\": \"Add a tune to my elrow Guest List\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_VahZ-O7JXU"
      },
      "source": [
        "## Load Tokenizer from transformers\n",
        "\n",
        "We will use a pretrained bert model `bert-base-cased` for both Tokenizer and our classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA8sh4pLVT84"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQFs80Rg7jj4"
      },
      "source": [
        "# Encode texts from the dataset\n",
        "\n",
        "We have to encode the texts using the tokenizer to create tensors for training the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpUnhqA2VT84",
        "outputId": "6875034f-9c9d-45f1-85df-683ff83bf6f7"
      },
      "source": [
        "# https://huggingface.co/transformers/preprocessing.html\n",
        "\n",
        "def encode_texts(tokenizer, texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "texts = [d.text for d in train_data]\n",
        "tds = encode_texts(tokenizer, texts)\n",
        "tds.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjaIbB7vVT84"
      },
      "source": [
        "encoded_texts = tds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8iBMHa577iQ"
      },
      "source": [
        "## Encode labels\n",
        "### Intents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1eTfXPQVT84",
        "outputId": "16ec4896-0d71-40b8-e724-99909199c166"
      },
      "source": [
        "\n",
        "intents = [d.intent for d in train_data]\n",
        "intent_names = list(set(intents))\n",
        "intent_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AddToPlaylist',\n",
              " 'BookRestaurant',\n",
              " 'GetWeather',\n",
              " 'RateBook',\n",
              " 'PlayMusic',\n",
              " 'SearchScreeningEvent',\n",
              " 'SearchCreativeWork']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDCv98XHVT84",
        "outputId": "3edcd2f8-0092-4c9b-9750-2a157dc7b90d"
      },
      "source": [
        "intent_map = dict() # index -> intent\n",
        "for idx, ui in enumerate(intent_names):\n",
        "    intent_map[ui] = idx\n",
        "intent_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AddToPlaylist': 0,\n",
              " 'BookRestaurant': 1,\n",
              " 'GetWeather': 2,\n",
              " 'PlayMusic': 4,\n",
              " 'RateBook': 3,\n",
              " 'SearchCreativeWork': 6,\n",
              " 'SearchScreeningEvent': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-PxXNWcVT84"
      },
      "source": [
        "# map to train_data values\n",
        "def encode_intents(intents, intent_map):\n",
        "    encoded = []\n",
        "    for i in intents:\n",
        "        encoded.append(intent_map[i])\n",
        "    # convert to tf tensor\n",
        "    return tf.convert_to_tensor(encoded, dtype=\"int32\")\n",
        "\n",
        "encoded_intents = encode_intents(intents, intent_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j0i00AW8gjA"
      },
      "source": [
        "### Slots\n",
        "\n",
        "To padd all the texts to the same length, the tokenizer will use special characters. To handle those we need to add <PAD> to slots_names. It can be some other symbol as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNW91LSgVT84",
        "outputId": "2bf96f17-a2f2-45b0-89e9-0111a10ad8fc"
      },
      "source": [
        "# encode slots\n",
        "slot_names = set()\n",
        "for td in train_data:\n",
        "    slots = td.slots\n",
        "    for slot in slots:\n",
        "        slot_names.add(slot)\n",
        "slot_names = list(slot_names)\n",
        "slot_names.insert(0, \"<PAD>\")\n",
        "slot_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PAD>',\n",
              " 'spatial_relation',\n",
              " 'music_item',\n",
              " 'object_name',\n",
              " 'geographic_poi',\n",
              " 'service',\n",
              " 'artist',\n",
              " 'playlist',\n",
              " 'object_part_of_series_type',\n",
              " 'playlist_owner',\n",
              " 'sort',\n",
              " 'cuisine',\n",
              " 'state',\n",
              " 'year',\n",
              " 'rating_unit',\n",
              " 'location_name',\n",
              " 'restaurant_name',\n",
              " 'object_type',\n",
              " 'country',\n",
              " 'object_select',\n",
              " 'timeRange',\n",
              " 'album',\n",
              " 'entity_name',\n",
              " 'movie_type',\n",
              " 'served_dish',\n",
              " 'city',\n",
              " 'poi',\n",
              " 'movie_name',\n",
              " 'party_size_number',\n",
              " 'genre',\n",
              " 'party_size_description',\n",
              " 'restaurant_type',\n",
              " 'object_location_type',\n",
              " 'best_rating',\n",
              " 'track',\n",
              " 'condition_description',\n",
              " 'rating_value',\n",
              " 'facility',\n",
              " 'current_location',\n",
              " 'condition_temperature']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fv7aVEoVT84",
        "outputId": "80e71fc8-08e5-4602-ce97-32f81a62366e"
      },
      "source": [
        "slot_map = dict() # slot -> index\n",
        "for idx, us in enumerate(slot_names):\n",
        "    slot_map[us] = idx\n",
        "slot_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<PAD>': 0,\n",
              " 'album': 21,\n",
              " 'artist': 6,\n",
              " 'best_rating': 33,\n",
              " 'city': 25,\n",
              " 'condition_description': 35,\n",
              " 'condition_temperature': 39,\n",
              " 'country': 18,\n",
              " 'cuisine': 11,\n",
              " 'current_location': 38,\n",
              " 'entity_name': 22,\n",
              " 'facility': 37,\n",
              " 'genre': 29,\n",
              " 'geographic_poi': 4,\n",
              " 'location_name': 15,\n",
              " 'movie_name': 27,\n",
              " 'movie_type': 23,\n",
              " 'music_item': 2,\n",
              " 'object_location_type': 32,\n",
              " 'object_name': 3,\n",
              " 'object_part_of_series_type': 8,\n",
              " 'object_select': 19,\n",
              " 'object_type': 17,\n",
              " 'party_size_description': 30,\n",
              " 'party_size_number': 28,\n",
              " 'playlist': 7,\n",
              " 'playlist_owner': 9,\n",
              " 'poi': 26,\n",
              " 'rating_unit': 14,\n",
              " 'rating_value': 36,\n",
              " 'restaurant_name': 16,\n",
              " 'restaurant_type': 31,\n",
              " 'served_dish': 24,\n",
              " 'service': 5,\n",
              " 'sort': 10,\n",
              " 'spatial_relation': 1,\n",
              " 'state': 12,\n",
              " 'timeRange': 20,\n",
              " 'track': 34,\n",
              " 'year': 13}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62lsuEZoVT84",
        "outputId": "7d5b610d-64b1-4c16-ce8a-e578b8887be8"
      },
      "source": [
        "# gets slot name from its values\n",
        "def get_slot_from_word(word, slot_dict):\n",
        "    for slot_label,value in slot_dict.items():\n",
        "        if word in value.split():\n",
        "            return slot_label\n",
        "    return None\n",
        "\n",
        "print(train_data[0].text)\n",
        "print(train_data[0].slots)\n",
        "print(\"slot_name for my is : \", get_slot_from_word(\"my\", train_data[0].slots))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Add a tune to my elrow Guest List\n",
            "{'music_item': 'tune', 'playlist_owner': 'my', 'playlist': 'elrow Guest List'}\n",
            "slot_name for my is :  playlist_owner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VUnAC8-VT84"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# find the max encoded test length\n",
        "# tokenizer pads all texts to same length anyway so\n",
        "# just get the length of the first one's input_ids\n",
        "max_len = len(encoded_texts[\"input_ids\"][0])\n",
        "\n",
        "def encode_slots(all_slots, all_texts, \n",
        "                 toknizer, slot_map, max_len=max_len):\n",
        "    encoded_slots = np.zeros(shape=(len(all_texts), max_len), dtype=np.int32)\n",
        "    \n",
        "    for idx, text in enumerate(all_texts):\n",
        "        enc = [] # for this idx, to be added at the end to encoded_slots\n",
        "        \n",
        "        # slot names for this idx\n",
        "        slot_names = all_slots[idx]\n",
        "        \n",
        "        # raw word tokens\n",
        "        # not using bert for this block because bert uses\n",
        "        # a wordpiece tokenizer which will make \n",
        "        # the slot label to word mapping\n",
        "        # difficult\n",
        "        raw_tokens = text.split()\n",
        "\n",
        "        # words or slot_values associated with a certain\n",
        "        # slot_name are contained in the values of the\n",
        "        # dict slots_names\n",
        "        # now this becomes a two way lookup\n",
        "        # first we check if a word belongs to any\n",
        "        # slot label or not and then we add the value from\n",
        "        # slot map to encoded for that word\n",
        "        for rt in raw_tokens:\n",
        "            # use bert tokenizer\n",
        "            # to get wordpiece tokens\n",
        "            bert_tokens = tokenizer.tokenize(rt)\n",
        "            \n",
        "            # find the slot name for a token\n",
        "            rt_slot_name = get_slot_from_word(rt, slot_names)\n",
        "            if rt_slot_name is not None:\n",
        "                # fill with the slot_map value for all ber tokens for rt\n",
        "                enc.append(slot_map[rt_slot_name])\n",
        "                enc.extend([slot_map[rt_slot_name]] * (len(bert_tokens) - 1))\n",
        "\n",
        "            else:\n",
        "                # rt is not associated with any slot name\n",
        "                enc.append(0)\n",
        "\n",
        "        \n",
        "        # now add to encoded_slots\n",
        "        # ignore the first and the last elements\n",
        "        # in encoded text as they're special chars\n",
        "        encoded_slots[idx, 1:len(enc)+1] = enc\n",
        "    \n",
        "    return encoded_slots\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Hj-St4VT84"
      },
      "source": [
        "all_slots = [td.slots for td in train_data]\n",
        "all_texts = [td.text for td in train_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIEsMzT8VT84"
      },
      "source": [
        "encoded_slots = encode_slots(all_slots, all_texts, tokenizer, slot_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw9aA2_gVT84",
        "outputId": "803f542d-6d20-43c5-92ea-8afdcfae224c"
      },
      "source": [
        "encoded_slots[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 2, 0, 9, 7, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Oahd4cP90ms"
      },
      "source": [
        "## Classifier Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8zokKeJ-RGI"
      },
      "source": [
        "### Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcmMMQaLVT84"
      },
      "source": [
        "from transformers import TFBertModel\n",
        "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "class JointIntentAndSlotFillingModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n",
        "                 model_name=model_name, dropout_prob=0.1):\n",
        "        super().__init__(name=\"joint_intent_slot\")\n",
        "        self.bert = TFBertModel.from_pretrained(model_name)\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "        self.intent_classifier = Dense(intent_num_labels,\n",
        "                                       name=\"intent_classifier\")\n",
        "        self.slot_classifier = Dense(slot_num_labels,\n",
        "                                     name=\"slot_classifier\")\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # two outputs from BERT\n",
        "        trained_bert = self.bert(inputs, **kwargs)\n",
        "        pooled_output = trained_bert.pooler_output\n",
        "        sequence_output = trained_bert.last_hidden_state\n",
        "        \n",
        "        # sequence_output will be used for slot_filling / classification\n",
        "        sequence_output = self.dropout(sequence_output,\n",
        "                                       training=kwargs.get(\"training\", False))\n",
        "        slot_logits = self.slot_classifier(sequence_output)\n",
        "\n",
        "        # pooled_output for intent classification\n",
        "        pooled_output = self.dropout(pooled_output,\n",
        "                                     training=kwargs.get(\"training\", False))\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return slot_logits, intent_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMpHQUuwVT84",
        "outputId": "0e25cd63-31b1-40a5-8288-8ba9191dc204"
      },
      "source": [
        "joint_model = JointIntentAndSlotFillingModel(\n",
        "    intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaI_qVxI-Xo4"
      },
      "source": [
        "### Hyperparams, Optimizer and Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZeZf3JVT84"
      },
      "source": [
        "opt = Adam(learning_rate=3e-5, epsilon=1e-08)\n",
        "\n",
        "# two outputs, one for slots, another for intents\n",
        "# we have to fine tune for both\n",
        "losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
        "          SparseCategoricalCrossentropy(from_logits=True)]\n",
        "\n",
        "metrics = [SparseCategoricalAccuracy(\"accuracy\")]\n",
        "# compile model\n",
        "joint_model.compile(optimizer=opt, loss=losses, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogJCgyMG-o4A"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uae9vd77VT84",
        "outputId": "c531eae4-781a-4b2d-94a6-0c9a09b567f5"
      },
      "source": [
        "x = {\"input_ids\": encoded_texts[\"input_ids\"], \"token_type_ids\": encoded_texts[\"token_type_ids\"],  \"attention_mask\": encoded_texts[\"attention_mask\"]}\n",
        "\n",
        "history = joint_model.fit(\n",
        "    x, (encoded_slots, encoded_intents), epochs=2, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f18a67296c8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f18c3b86110> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f18a67296c8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f18c3b86110> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f18c1a61b70> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7f18c1a61b70> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "316/316 [==============================] - 126s 294ms/step - loss: 1.3801 - output_1_loss: 0.6952 - output_2_loss: 0.6849 - output_1_accuracy: 0.8540 - output_2_accuracy: 0.7662\n",
            "Epoch 2/2\n",
            "316/316 [==============================] - 93s 294ms/step - loss: 0.1442 - output_1_loss: 0.1101 - output_2_loss: 0.0341 - output_1_accuracy: 0.9680 - output_2_accuracy: 0.9893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOSkQ6mZ-sMg"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZqMiC_gZM5s"
      },
      "source": [
        "def nlu(text, tokenizer, model, intent_names, slot_names):\n",
        "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
        "    outputs = model(inputs)\n",
        "    slot_logits, intent_logits = outputs\n",
        "\n",
        "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, :]\n",
        "    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
        "\n",
        "    info = {\"intent\": intent_names[intent_id], \"slots\": {}}\n",
        "\n",
        "    out_dict = {}\n",
        "    # get all slot names and add to out_dict as keys\n",
        "    predicted_slots = set([slot_names[s] for s in slot_ids if s != 0])\n",
        "    for ps in predicted_slots:\n",
        "      out_dict[ps] = []\n",
        "\n",
        "    # check if the text starts with a small letter\n",
        "    if text[0].islower():\n",
        "      tokens = tokenizer.tokenize(text, add_special_tokens=True)\n",
        "    else:\n",
        "      tokens = tokenizer.tokenize(text)\n",
        "    for token, slot_id in zip(tokens, slot_ids):\n",
        "        # add all to out_dict\n",
        "        slot_name = slot_names[slot_id]\n",
        "\n",
        "        if slot_name == \"<PAD>\":\n",
        "            continue\n",
        "\n",
        "        # collect tokens\n",
        "        collected_tokens = [token]\n",
        "        idx = tokens.index(token)\n",
        "\n",
        "        # see if it starts with ##\n",
        "        # then it belongs to the previous token\n",
        "        if token.startswith(\"##\"):\n",
        "          # check if the token already exists or not\n",
        "          if tokens[idx - 1] not in out_dict[slot_name]:\n",
        "            collected_tokens.insert(0, tokens[idx - 1])\n",
        "\n",
        "        # add collected tokens to slots\n",
        "        out_dict[slot_name].extend(collected_tokens)\n",
        "\n",
        "    # process out_dict\n",
        "    for slot_name in out_dict:\n",
        "        tokens = out_dict[slot_name]\n",
        "        slot_value = tokenizer.convert_tokens_to_string(tokens)\n",
        "\n",
        "        info[\"slots\"][slot_name] = slot_value.strip()\n",
        "\n",
        "    return info\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzuZBVpu_K9Q",
        "outputId": "b9b45e85-192c-432e-8aa7-bf7ab28171a3"
      },
      "source": [
        "nlu(\"add Madchild to Electro Latino\", tokenizer, joint_model, \n",
        "    intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'AddToPlaylist',\n",
              " 'slots': {'entity_name': 'Madchild', 'playlist': 'Electro Latino'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXSXyLFV_fAE",
        "outputId": "70b76afb-a753-4ae0-b0d0-a66178b0787c"
      },
      "source": [
        "nlu(\"add Brian May to my Reggae Infusions list\", tokenizer, joint_model, \n",
        "    intent_names, slot_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'AddToPlaylist',\n",
              " 'slots': {'artist': 'Brian May',\n",
              "  'playlist': 'Reggae Infusions',\n",
              "  'playlist_owner': 'my'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs6x7wmDVT84",
        "outputId": "a2ee8a49-84a1-497a-be22-28b05ffeae94"
      },
      "source": [
        "import calendar\n",
        "import time\n",
        "\n",
        "# to generate timestamps for prediction file\n",
        "def get_time_stamp():\n",
        "    ts = calendar.timegm(time.gmtime())\n",
        "    return ts\n",
        "\n",
        "get_time_stamp()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1611939468"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWCPwzLP_rQc"
      },
      "source": [
        "## Generate prediction.json\n",
        "\n",
        "This section creates a file containing all the prediction results for inputs from dev.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ikoiObKAYWQ"
      },
      "source": [
        "def read_dev_data(file=\"dev.json\"):\n",
        "    dev_texts = []\n",
        "    with open(file, \"r\", encoding=\"utf-8\") as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "        for k in data.keys():\n",
        "          text = data[k][\"text\"]\n",
        "          dev_texts.append(text)\n",
        "          \n",
        "    return dev_texts\n",
        "dev_texts = read_dev_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVAO36SFCTRc",
        "outputId": "7ade69dc-7753-408f-98fd-c16011b4eb1a"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "results = []\n",
        "for i in tqdm(range(len(dev_texts))):\n",
        "    res = nlu(dev_texts[i], tokenizer, joint_model, intent_names, slot_names)\n",
        "    results.append(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2887/2887 [02:58<00:00, 16.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85iJGRUIDWEc"
      },
      "source": [
        "# process results\n",
        "results_dict = dict()\n",
        "\n",
        "for idx, res in enumerate(results):\n",
        "    results_dict[str(idx)] = res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blUA-FCxEwbQ"
      },
      "source": [
        "with open(\"prediction.json\", \"w\") as f:\n",
        "    json.dump(results_dict, f, indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRyM8MjiF7vs",
        "outputId": "9862523d-e19d-44b6-ec53-0f4903306f01"
      },
      "source": [
        "!head prediction.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"0\": {\n",
            "    \"intent\": \"AddToPlaylist\",\n",
            "    \"slots\": {\n",
            "      \"entity_name\": \"changes & things\",\n",
            "      \"playlist\": \"hot 50\"\n",
            "    }\n",
            "  },\n",
            "  \"1\": {\n",
            "    \"intent\": \"AddToPlaylist\",\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}